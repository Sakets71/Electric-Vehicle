{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e69248-c6a4-47d2-a16c-92792456c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 8: Hyperparameter Tuning with GridSearch + Optuna\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "import joblib  # for saving models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a7e42e3-dfe2-4292-9c6e-a9e072bae455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (492, 8)\n",
      "Train shape: (393, 7) Test shape: (99, 7)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Saket\\OneDrive\\Desktop\\4th sem\\python\\EDA\\EV_Market_Analysis\\data\\processed\\ev_merged_cleaned.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "data.head()\n",
    "\n",
    "# Features & Target\n",
    "X = data.drop(columns=[\"ev_share\"])\n",
    "y = data[\"ev_share\"]\n",
    "\n",
    "# Train/Test split (same as Day 7 for consistency)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43cd0bae-7f8f-48da-b013-3f5a748d0cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5-Fold cross-validation for reliable evaluation.\n"
     ]
    }
   ],
   "source": [
    "# K-Fold cross validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"Using 5-Fold cross-validation for reliable evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea007723-0e61-4ef6-8aca-b4c566478189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (393, 5) Test shape: (99, 5)\n",
      "Features used: ['year', 'population', 'total_chargers', 'charger_density_per_100k', 'population_million']\n"
     ]
    }
   ],
   "source": [
    "# Drop text columns that can't be used directly in ML models\n",
    "X = data.drop(columns=[\"ev_share\", \"country\", \"iso_code\"])\n",
    "\n",
    "# Target\n",
    "y = data[\"ev_share\"]\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "print(\"Features used:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e0cd4b1-13c9-412f-ab67-84a010763aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best R2 Score: 0.7174625610221124\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: GridSearch for Random Forest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                 # 5-fold cross-validation\n",
    "    n_jobs=-1,            # use all CPU cores\n",
    "    scoring=\"r2\",         # RÂ² score for regression\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best R2 Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f67cda1-f94f-4846-a0c6-715727d3cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test R2: 0.4493579366669028\n",
      "Random Forest Test RMSE: 10.164496519513278\n"
     ]
    }
   ],
   "source": [
    "# Get best estimator\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Test R2:\", r2_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a081f84-3747-41ff-a3b7-4d477af9790d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 09:57:21,033] A new study created in memory with name: no-name-cf2c1cc3-7f5b-4b5a-98b9-86bf15cbf2e5\n",
      "[I 2025-08-23 09:57:24,904] Trial 0 finished with value: 0.5688199539687715 and parameters: {'n_estimators': 391, 'max_depth': 5, 'learning_rate': 0.04407900970947291, 'subsample': 0.5414041626922883, 'colsample_bytree': 0.9244204173348898}. Best is trial 0 with value: 0.5688199539687715.\n",
      "[I 2025-08-23 09:57:26,423] Trial 1 finished with value: 0.41504849817875566 and parameters: {'n_estimators': 283, 'max_depth': 3, 'learning_rate': 0.011318579217678941, 'subsample': 0.5503326179649952, 'colsample_bytree': 0.5387266662116148}. Best is trial 0 with value: 0.5688199539687715.\n",
      "[I 2025-08-23 09:57:30,060] Trial 2 finished with value: 0.30058923414916305 and parameters: {'n_estimators': 487, 'max_depth': 11, 'learning_rate': 0.1227226687341205, 'subsample': 0.9509812798709094, 'colsample_bytree': 0.5727014410346902}. Best is trial 0 with value: 0.5688199539687715.\n",
      "[I 2025-08-23 09:57:33,299] Trial 3 finished with value: 0.47008642600672124 and parameters: {'n_estimators': 357, 'max_depth': 8, 'learning_rate': 0.07841877257576117, 'subsample': 0.6235434295192295, 'colsample_bytree': 0.6384294097248822}. Best is trial 0 with value: 0.5688199539687715.\n",
      "[I 2025-08-23 09:57:35,468] Trial 4 finished with value: 0.5681370832611943 and parameters: {'n_estimators': 416, 'max_depth': 7, 'learning_rate': 0.04817202906911172, 'subsample': 0.5722469388940363, 'colsample_bytree': 0.8854664929661674}. Best is trial 0 with value: 0.5688199539687715.\n",
      "[I 2025-08-23 09:57:37,292] Trial 5 finished with value: 0.4917640463382179 and parameters: {'n_estimators': 407, 'max_depth': 9, 'learning_rate': 0.03238840591714177, 'subsample': 0.5454192451511033, 'colsample_bytree': 0.7064356478464195}. Best is trial 0 with value: 0.5688199539687715.\n",
      "[I 2025-08-23 09:57:38,681] Trial 6 finished with value: 0.5702444858769982 and parameters: {'n_estimators': 360, 'max_depth': 5, 'learning_rate': 0.20881603929353734, 'subsample': 0.6544564574878424, 'colsample_bytree': 0.9047057147501805}. Best is trial 6 with value: 0.5702444858769982.\n",
      "[I 2025-08-23 09:57:40,643] Trial 7 finished with value: 0.39139123772418605 and parameters: {'n_estimators': 183, 'max_depth': 11, 'learning_rate': 0.20946810868186688, 'subsample': 0.9049149881681273, 'colsample_bytree': 0.7066053255728412}. Best is trial 6 with value: 0.5702444858769982.\n",
      "[I 2025-08-23 09:57:41,375] Trial 8 finished with value: 0.5251257732045607 and parameters: {'n_estimators': 268, 'max_depth': 4, 'learning_rate': 0.09735165642016325, 'subsample': 0.7629500066687481, 'colsample_bytree': 0.9694932589562337}. Best is trial 6 with value: 0.5702444858769982.\n",
      "[I 2025-08-23 09:57:42,319] Trial 9 finished with value: 0.5648135264401417 and parameters: {'n_estimators': 141, 'max_depth': 7, 'learning_rate': 0.09895698081061924, 'subsample': 0.9896312933493414, 'colsample_bytree': 0.843081490901834}. Best is trial 6 with value: 0.5702444858769982.\n",
      "[I 2025-08-23 09:57:42,946] Trial 10 finished with value: 0.5523565973152116 and parameters: {'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.2957670510847723, 'subsample': 0.7071535788350986, 'colsample_bytree': 0.8045394628015857}. Best is trial 6 with value: 0.5702444858769982.\n",
      "[I 2025-08-23 09:57:44,178] Trial 11 finished with value: 0.5513136128809997 and parameters: {'n_estimators': 355, 'max_depth': 5, 'learning_rate': 0.1835777344534012, 'subsample': 0.6751469474078953, 'colsample_bytree': 0.9993329230731787}. Best is trial 6 with value: 0.5702444858769982.\n",
      "[I 2025-08-23 09:57:45,885] Trial 12 finished with value: 0.6103579267679062 and parameters: {'n_estimators': 499, 'max_depth': 6, 'learning_rate': 0.24592410416690502, 'subsample': 0.8017809701379595, 'colsample_bytree': 0.9100402056216096}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:57:47,130] Trial 13 finished with value: 0.40917752446156425 and parameters: {'n_estimators': 470, 'max_depth': 6, 'learning_rate': 0.2693337769114275, 'subsample': 0.8087372700925541, 'colsample_bytree': 0.7938202938821506}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:57:47,726] Trial 14 finished with value: 0.5301429121423583 and parameters: {'n_estimators': 329, 'max_depth': 3, 'learning_rate': 0.23312128022350545, 'subsample': 0.8705097064067538, 'colsample_bytree': 0.9013442699707831}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:57:51,291] Trial 15 finished with value: 0.5682003199308698 and parameters: {'n_estimators': 457, 'max_depth': 9, 'learning_rate': 0.16223439478755336, 'subsample': 0.8205688058128481, 'colsample_bytree': 0.846496931246354}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:57:53,046] Trial 16 finished with value: 0.5798648850980941 and parameters: {'n_estimators': 498, 'max_depth': 6, 'learning_rate': 0.23935133520313062, 'subsample': 0.6556597233266204, 'colsample_bytree': 0.9398588044524933}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:57:55,163] Trial 17 finished with value: 0.5750010727387057 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.25324793566962767, 'subsample': 0.7259800105134537, 'colsample_bytree': 0.9634079378280723}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:57:56,310] Trial 18 finished with value: 0.4081306243629054 and parameters: {'n_estimators': 438, 'max_depth': 6, 'learning_rate': 0.29538597217061685, 'subsample': 0.7791325429035422, 'colsample_bytree': 0.7418485392367825}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:57:58,908] Trial 19 finished with value: 0.5492244580742238 and parameters: {'n_estimators': 441, 'max_depth': 9, 'learning_rate': 0.2314498455129088, 'subsample': 0.6033165815100893, 'colsample_bytree': 0.8476782137047668}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:00,398] Trial 20 finished with value: 0.562033755784583 and parameters: {'n_estimators': 104, 'max_depth': 12, 'learning_rate': 0.1581426375069248, 'subsample': 0.8725556451644462, 'colsample_bytree': 0.9305233446382773}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:02,623] Trial 21 finished with value: 0.5858907383074657 and parameters: {'n_estimators': 495, 'max_depth': 8, 'learning_rate': 0.2604318996610317, 'subsample': 0.7165156461310173, 'colsample_bytree': 0.9735316571773514}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:04,142] Trial 22 finished with value: 0.5933167867664851 and parameters: {'n_estimators': 495, 'max_depth': 6, 'learning_rate': 0.26264025380730227, 'subsample': 0.6895128367407433, 'colsample_bytree': 0.9912495372723612}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:05,733] Trial 23 finished with value: 0.5843011241089149 and parameters: {'n_estimators': 456, 'max_depth': 7, 'learning_rate': 0.27306792609255887, 'subsample': 0.7154485921859323, 'colsample_bytree': 0.9792741409291718}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:07,729] Trial 24 finished with value: 0.5733008277005317 and parameters: {'n_estimators': 424, 'max_depth': 8, 'learning_rate': 0.1948226727103631, 'subsample': 0.8072307493280454, 'colsample_bytree': 0.998696079715894}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:09,423] Trial 25 finished with value: 0.5864667332951015 and parameters: {'n_estimators': 381, 'max_depth': 10, 'learning_rate': 0.27107542772856996, 'subsample': 0.752759167330561, 'colsample_bytree': 0.8875131733156327}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:10,836] Trial 26 finished with value: 0.5539040835034792 and parameters: {'n_estimators': 389, 'max_depth': 10, 'learning_rate': 0.29644941831651417, 'subsample': 0.8423641723024712, 'colsample_bytree': 0.8734676449312373}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:11,620] Trial 27 finished with value: 0.5375815292388003 and parameters: {'n_estimators': 323, 'max_depth': 4, 'learning_rate': 0.2183058768691328, 'subsample': 0.7572754937601177, 'colsample_bytree': 0.8012073959154848}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:13,097] Trial 28 finished with value: 0.5376149076284902 and parameters: {'n_estimators': 229, 'max_depth': 10, 'learning_rate': 0.2766895325394334, 'subsample': 0.5012990121282488, 'colsample_bytree': 0.9327889451447522}. Best is trial 12 with value: 0.6103579267679062.\n",
      "[I 2025-08-23 09:58:14,451] Trial 29 finished with value: 0.5959108088374714 and parameters: {'n_estimators': 394, 'max_depth': 6, 'learning_rate': 0.24463615805602365, 'subsample': 0.7842714278188041, 'colsample_bytree': 0.9375672096078298}. Best is trial 12 with value: 0.6103579267679062.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB Params: {'n_estimators': 499, 'max_depth': 6, 'learning_rate': 0.24592410416690502, 'subsample': 0.8017809701379595, 'colsample_bytree': 0.9100402056216096}\n",
      "Best XGB CV Score: 0.6103579267679062\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**params, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"r2\", n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"Best XGB Params:\", study.best_params)\n",
    "print(\"Best XGB CV Score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caa621b6-c444-4339-a7c8-c625af4abd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test R2: 0.546971568886504\n",
      "XGBoost Test RMSE: 9.219638837108075\n"
     ]
    }
   ],
   "source": [
    "# Train XGB with best params\n",
    "best_xgb = XGBRegressor(**study.best_params, random_state=42)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Test R2:\", r2_score(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_xgb)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb5dbc5a-2aa8-43f8-ac13-1a5b758cf409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved for Day 9 analysis!\n"
     ]
    }
   ],
   "source": [
    "# Save tuned models\n",
    "joblib.dump(best_rf, r\"C:\\Users\\Saket\\OneDrive\\Desktop\\4th sem\\python\\EDA\\EV_Market_Analysis/best_random_forest.pkl\")\n",
    "joblib.dump(best_xgb, r\"C:\\Users\\Saket\\OneDrive\\Desktop\\4th sem\\python\\EDA\\EV_Market_Analysis/best_xgboost.pkl\")\n",
    "\n",
    "print(\"Models saved for Day 9 analysis!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e10c70b-333e-438d-b14c-4c5a932a093a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
